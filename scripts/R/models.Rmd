---
title: "Modeling Crashes with Three Sets of Connectivity Measures"
author: "Jiahua Chen"
date: "2024-01-04"
output: 
  html_document:
    theme: flatly
    code_folding: hide
    toc: yes
    toc_float:
      collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages = c('sf','tidyverse','MASS',"spatialreg","spdep","modelsummary")
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

# Set up

## Read in

```{r class.source = 'fold-show'}
#newest version: with end nodes
var <- st_read("../../scripts/python/outputs/no end nodes/connectivity_blocks/connectivity_blocks.shp")
var_block <- st_read("../../data/block_2349_v2/block_2349.shp")

#turn shp into df
var_df <- var %>%  
  st_drop_geometry()
```

## Clean up

```{r class.source = 'fold-show'}
#common variables
common_var <- var_df %>% 
  dplyr::select(crashes, trips, are_km2 ,slope, pp_dn_2 , phisp, prc_low, incm_md, unmplyd, fem_prc, vtrns_p, wht_prc)
common_var[,-c(1,2)] <- scale(common_var[,-c(1,2)]) #remove those don't need scaling: GEOID, trips, crashes, factor of phisp&income 

#three sets of connectivity measures
connectivity_measures <- list(scale(data.frame(var_df$cnnctvt)),
                              scale(data.frame(var_df$b_net_dens,var_df$b_gamma,var_df$b_cover,var_df$b_int_dens,var_df$b_complex)),
                              scale(data.frame(var_df$ls_net_den,var_df$ls_gamma,var_df$ls_cover,var_df$ls_int_den,var_df$ls_complex)))

```

# Block level

```{r}
road_network <- st_read("../../data/slope/slope.shp") 
polygons <- var_block

crs_x <- st_crs(road_network)
crs_y <- st_crs(polygons)

if (!identical(crs_x, crs_y)) {
  polygons <- st_transform(polygons, crs = crs_x)
}

library(dplyr)
library(progress)

# Create an empty vector to store the weighted average slopes
weighted_average_slopes <- numeric(length = nrow(polygons))

# Iterate over each polygon
for (i in 1:nrow(polygons)) {
  polygon <- polygons[i, ]
  
  # Extract road segments within the polygon
  road_segments_within_polygon <- st_intersection(road_network, polygon)
  
  # Calculate weighted average slope
  if (nrow(road_segments_within_polygon) > 0) {
    weighted_average_slopes[i] <- road_segments_within_polygon %>%
      mutate(weighted_slope = length * slope_medi) %>%
      summarize(weighted_average_slope = sum(weighted_slope) / sum(length)) %>%
      pull(weighted_average_slope)
  } else {
    weighted_average_slopes[i] <- NA
  }
  
  # Print the current progress
  cat("Processing polygon", i, "of", nrow(polygons), "\n")
}

var_block$slope <- weighted_average_slopes

#### map visualization
ggplot() +
  geom_sf(data = var_block, aes(fill = "slope"), color = NA) +
  scale_fill_distiller(palette = "PuOr", direction = -1) +
  theme_void()
```

```{r}
block <- var_block %>% 
  dplyr::select(BLOCKID10,POP10,OVERALL_SC,sum_total_,sum_allroa,Point_Coun,slope,Shape_Area) %>%
  scale(OVERALL_SC,POP10,slope,Shape_Area) %>% 
  drop_na(sum_total_) %>% 
  filter(sum_total_!=0) %>% 
  mutate(rate=Point_Coun/sum_total_) %>% 
  st_drop_geometry

model.block <- glm.nb(Point_Coun ~ OVERALL_SC + slope + Shape_Area + sum_total_, data = block)

summary(model.block)

cor.test(block$rate,block$OVERALL_SC)

install.packages("ggpubr")
library(ggpubr)
ggscatter(block, x = "rate", y = "Point_Coun")
   #color = "cyl", shape = "cyl",
   #palette = c("#00AFBB", "#E7B800", "#FC4E07"),
   #ellipse = TRUE, mean.point = TRUE,
   #star.plot = TRUE))
```

"

# **Neighborhood level**

## Null Model

```{r}
(model.null <- glm.nb(crashes ~ offset(log(trips)), data = var_df))
model.null.list <- list(model.null)
```

## Model with connectivity indices

```{r}
# run models for two different connectivity measure
# set up for loop
# install.packages("rlist")
library(rlist)
model_results_conn <- list()
model_results_all <- list()
df_list <- list()
for (i in seq_along(connectivity_measures)) {
  current_measure <- connectivity_measures[[i]]
  # model for only offset + connectivity measures
  df <- data.frame(current_measure,"trips"=common_var$trips,"crashes"=common_var$crashes, "slope" =common_var$slope, "area" = common_var$are_km2)
  new_model_conn <- glm.nb(crashes ~ . -trips + offset(log(trips)),data = df)
  # model for all variables
  df <- cbind(current_measure,common_var)
  df_list <- list.append(df_list,df)
  new_model_all <- glm.nb(crashes ~ . -trips -prc_low + offset(log(trips)),data = df)
  # append model results to the list for making tables
  model_results_conn <- list.append(model_results_conn,new_model_conn)
  model_results_all <- list.append(model_results_all,new_model_all)
}
modelsummary(model_results_conn,stars = TRUE)
modelsummary(model_results_all,stars = TRUE)
```

### Test SAC

All model residuals have a moran'I value at significance level p \> 0.5, so no spatial autocorrelation! Don't need to include spatial error term

```{r}
# test spatial autocorrelation 
# Create a spatial weight matrix
weight_matrix <- poly2nb(var, row.names = var$GEOID)  # Adjust row.names to match your shapefile
weight_listw <- nb2listw(weight_matrix, style = "W")
moran_results <- list()
for (i in seq_along(model_results_all)){
  new_moran <- lm.morantest(model_results_all[[i]],weight_listw)
  moran_results <- list.append(moran_results,new_moran)
  print(new_moran$p.value)
}
```

### Results

For model with only connectivity measures, among the significant coefficients:

1.  Model1-PFB: connectivity score (+)
2.  Model2-bike_network: network density (+), intersection density (-), complexity (-)
3.  Model3-low_stress_network: network density (+), complexity (-)

For model with only all variables, among the significant coefficients:

1.  Model1-PFB: connectivity score (+)
2.  Model2-bike_network: gamma (-)
3.  Model3-low_stress_network: coverage (-)

Notes: for model 2&3, might need to remove percentage_low_stress from the formula as it overlaps with the network coverage variable

## Model with interaction

```{r}
# interaction only for significant connectivity measures
# for now pfb_cnnctvt, b_gamma, ls_cover
model_results_int_sig <- list()
connectivity_measures_sig <- c("var_df.cnnctvt","var_df.ls_net_den","var_df.ls_cover")
for (i in seq_along(connectivity_measures)) {
  current_measure <- connectivity_measures[[i]]
  df <- cbind(current_measure,common_var)
  if (i==2){
    next
  }
  formula <- as.formula(paste("crashes ~. -trips -prc_low + offset(log(trips)) +",
    paste("phisp", connectivity_measures_sig[i], sep = "*")))
  new_model_int <- glm.nb(formula = formula,data = df)
  # append model results to the list for making tables
  model_results_int_sig <- list.append(model_results_int_sig,new_model_int)
}
modelsummary(model_results_int_sig,stars = TRUE)


# loop interaction for all connectivity measures
# set up for looping
model_results_int <- list()
for (i in seq_along(connectivity_measures)) {
  current_measure <- connectivity_measures[[i]]
  df <- cbind(current_measure,common_var)
  formula <- as.formula(paste("crashes ~. -trips -prc_low + offset(log(trips)) +",
    paste("phisp", colnames(connectivity_measures[[i]]), sep = "*",collapse = "+")))
  new_model_int <- glm.nb(formula = formula,data = df)
  # append model results to the list for making tables
  model_results_int <- list.append(model_results_int,new_model_int)
}
modelsummary(model_results_int,stars = TRUE)



```

### Test SAC

All model residuals have a moran'I value at significance level p \> 0.45, so no spatial autocorrelation! Don't need to include spatial error term

```{r}
# test spatial autocorrelation 
# Create a spatial weight matrix
model_results_int_all <- c(model_results_int,model_results_int_sig)
moran_results_int <- list()
for (i in seq_along(model_results_int_all)){
  new_moran <- lm.morantest(model_results_int_all[[i]],weight_listw)
  moran_results <- list.append(moran_results,new_moran)
  print(new_moran$p.value)
}
# all test p > 0.45, no spatial autocorrelation
```

### Results

For model with interaction of %Hispanic with significant connectivity measures, among the significant coefficients, all interactions are not significant.

For model with interaction of %Hispanic with all connectivity measures, among the significant coefficients:

1.  Model1-PFB: not significant
2.  Model2-bike_network: phisp\*gamma (+), phisp\*coverage(+)
3.  Model3-low_stress_network: phisp\*intersection_density (-)

## Output

```{r}
all_model <- c(model.null.list,model_results_conn,model_results_all,model_results_int_all)

#modelsummary(all_model,stars = TRUE,"result_tables/result_table_withnodes.docx")
modelsummary(all_model,stars = TRUE,"result_tables/result_table_nonodes.docx")
```

### Plot

```{r}
#install.packages("sjmisc")
#install.packages("sjPlot")
library(sjmisc)
library(sjPlot)

## only connnectivity measure
plot_model(model_results_conn[[1]])
plot_model(model_results_conn[[2]])
plot_model(model_results_conn[[3]])

#with demography
plot_model(model_results_all[[1]],group.terms = c(1,2,2,3,3,3,3,3,3,3))
plot_model(model_results_all[[2]],group.terms = c(1,1,1,1,1,2,2,3,3,3,3,3,3,3))
plot_model(model_results_all[[3]],group.terms = c(1,1,1,1,1,2,2,3,3,3,3,3,3,3))
```

```{r}
plot_model(model_results_all[[1]], type = "eff", terms = "var_df.cnnctvt",data=df_list[[1]])
```

```{r}
library(dplyr)
df <- df_list[[1]] %>% dplyr::select(-prc_low)

test.m <- glm.nb(crashes ~ var_df.cnnctvt + are_km2 + slope + pp_dn_2 + phisp + incm_md + unmplyd + fem_prc + vtrns_p + wht_prc + offset(log(trips)),data = df)

summary(test.m)

library(jtools)
effect_plot(test.m, 
            pred = phisp, 
            data=df,
            interval = TRUE,
            plot.points = TRUE, 
            jitter = 0.05)

```
