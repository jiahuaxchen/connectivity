{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700b1644-f495-4bcd-932e-a8440b898fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: geopandas in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: momepy in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: shapely in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: fiona>=1.8.21 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from geopandas) (1.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from geopandas) (23.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: libpysal>=4.6.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from momepy) (4.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from momepy) (4.66.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
      "Requirement already satisfied: click~=8.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (68.2.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from fiona>=1.8.21->geopandas) (6.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.2 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from libpysal>=4.6.0->momepy) (3.10.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.10 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from libpysal>=4.6.0->momepy) (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from libpysal>=4.6.0->momepy) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from libpysal>=4.6.0->momepy) (1.11.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from tqdm>=4.27.0->momepy) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from beautifulsoup4>=4.10->libpysal>=4.6.0->momepy) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from requests->libpysal>=4.6.0->momepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from requests->libpysal>=4.6.0->momepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danwillett\\appdata\\local\\anaconda3\\envs\\jiahua-connectivity\\lib\\site-packages (from requests->libpysal>=4.6.0->momepy) (1.26.18)\n"
     ]
    }
   ],
   "source": [
    "# installs packages into kernel, not environment\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy geopandas pandas matplotlib momepy networkx shapely numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f96b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import momepy\n",
    "import networkx as nx\n",
    "import shapely\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "output_folder = \"C:/Users/danwillett/Code/jiahua-connectivity/connectivity/scripts/python/outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9423e40d-0038-41ae-a6ad-139007f5f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_network_path = './places/Santa_barbara_county__California/bike_network_network.shp'\n",
    "bike_network = gpd.read_file(bike_network_path)\n",
    "\n",
    "low_stress_path = './places/Santa_barbara_county__California/low_stress_network_new.shp'\n",
    "low_stress = gpd.read_file(low_stress_path)\n",
    "low_stress = low_stress.to_crs(bike_network.crs)\n",
    "\n",
    "all_streets_path = './places/Santa_barbara_county__California/all_streets_network_new.shp'\n",
    "all_streets = gpd.read_file(all_streets_path)\n",
    "all_streets = all_streets.to_crs(bike_network.crs)\n",
    "\n",
    "block_path = '../../data/20231120_blockgroup/var1120.shp'\n",
    "blocks = gpd.read_file(block_path)\n",
    "blocks = blocks.to_crs(bike_network.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044ae37-3f0b-4123-8a4c-c3e05a18558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up roads in gpds\n",
    "\n",
    "# remove multilinestrings from the low_stress dataframe. These are small roads that have been breaks between them, \n",
    "# but aren't located on primary roads\n",
    "def remove_multis(shp_file, multi_output_name):\n",
    "    geoms = shp_file['geometry']\n",
    "    geomTypes = pd.Series([type(line) for line in geoms])\n",
    "    multiTypes = geoms.apply(lambda x: isinstance(x, shapely.geometry.multilinestring.MultiLineString))\n",
    "    multiLines = shp_file[multiTypes]\n",
    "    \n",
    "    if len(multiLines) > 0:\n",
    "        # save multiline polygons to see how many are removed and if they are important\n",
    "        output_shapefile_path = './outputs/' + multi_output_name\n",
    "        multiLines.to_file(output_shapefile_path, driver='ESRI Shapefile')\n",
    "    \n",
    "    return shp_file[~multiTypes]\n",
    "\n",
    "\n",
    "# remove polylines from gpds\n",
    "bike_polylines = remove_multis(bike_network, 'bike_multilines')\n",
    "low_stress_polylines = remove_multis(low_stress, 'low_stress_multilines')\n",
    "all_streets_polylines = remove_multis(all_streets, 'all_streets_multlines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d81cc-37f5-404e-963b-ad34647e91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating conductivity indicators\n",
    "# network density = (total length of bike links)/(block area)\n",
    "def calc_net_density(bike_edges, polygon):\n",
    "    total_len = sum(bike_edges['edge_length'])/1000 # covert to km\n",
    "    total_area = polygon['area'].values[0]/1000000 #convert to km2\n",
    "    net_density = total_len/total_area # need to figure out what my data layers are\n",
    "    return net_density\n",
    "\n",
    "# Gamma Connectivity (degree of connectivity) = edges/lmax, where lmax = 3(n-2)\n",
    "def calc_gamma(nodes, edges):\n",
    "    # gamma connectivity only works if there are 3 or more nodes\n",
    "    gamma_connectivity = (sum(edges['weights']))/(3*(len(nodes)-2)) if len(nodes) > 2 else None\n",
    "    if gamma_connectivity > 1:\n",
    "        gamma_connectivity = 1\n",
    "    return gamma_connectivity\n",
    "\n",
    "# Degree of network coverage (Number of bike links)/(number of street links)\n",
    "def calc_net_coverage(bike_edges, street_edges):\n",
    "    net_coverage = sum(bike_edges['weights'])/sum(street_edges['weights'])\n",
    "    \n",
    "    # there are small discrepancies in how simplification affects different network files\n",
    "    if net_coverage > 1:\n",
    "        net_coverage == 1\n",
    "    return net_coverage\n",
    "\n",
    "# Intersection density (Number of bike network intersections)/(block area)\n",
    "def calc_int_density(bike_nodes, polygon):\n",
    "    total_area = polygon['area'].values[0]/1000000 #convert to km2\n",
    "    int_density = len(bike_nodes)/total_area\n",
    "    return int_density\n",
    "\n",
    "# Degree of network complexity (Number of bike links)/(bike nodes)\n",
    "def calc_complexity(bike_edges, bike_nodes):\n",
    "    net_complexity = sum(bike_edges['weights'])/(len(bike_nodes)) if len(bike_nodes) > 0 else None\n",
    "    return net_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df09c0-436c-46c9-bc13-5f4a44a24837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all units in meters (from crs)\n",
    "\n",
    "# output census block shapefile path with appended connectivity indicator data\n",
    "output_blocks_path = './outputs/connectivity_blocks'\n",
    "\n",
    "# list to store connectivity indicators for each block\n",
    "# b = bike_network, l = low_stress\n",
    "connectivity_indicators_list = {\n",
    "        'GEOID': [],\n",
    "        'b_net_dens': [],\n",
    "        'ls_net_dens': [],\n",
    "        'b_gamma': [],\n",
    "        'ls_gamma': [],\n",
    "        'b_cover': [],\n",
    "        'ls_cover': [],\n",
    "        'b_int_dens': [],\n",
    "        'ls_int_dens': [],\n",
    "        'b_complex': [],\n",
    "        'ls_complex': []\n",
    "    }\n",
    "\n",
    "# store edges and nodes to visualize in arcgis\n",
    "bike_edges_list = []\n",
    "bike_nodes_list = []\n",
    "low_stress_edges_list = []\n",
    "low_stress_nodes_list = []\n",
    "street_edges_list = []\n",
    "street_nodes_list = []\n",
    "\n",
    "# iterate through each census block, calculating and storing connectivity indicators\n",
    "for index, row in blocks.iterrows():\n",
    "    row = row.to_frame().T # reshape row to be a dataframe with columns\n",
    "    id = row['GEOID'].values[0] # store unique GEOID of the current census block\n",
    "    polygon = gpd.GeoDataFrame(row, geometry='geometry', crs=blocks.crs)\n",
    "    \n",
    "    # select networks that reside in current block\n",
    "    clipped_bike = gpd.sjoin(bike_polylines, polygon, how='inner', op='intersects')\n",
    "    clipped_low_stress = gpd.sjoin(low_stress_polylines, polygon, how='inner', op='intersects')\n",
    "    clipped_streets = gpd.sjoin(all_streets_polylines, polygon, how='inner', op='intersects')\n",
    "\n",
    "    # find the new edge lengths of roads that are cut by block boundaries\n",
    "    clipped_bike_edge = bike_polylines.clip(polygon)\n",
    "    clipped_bike['edge_length'] = clipped_bike_edge['geometry'].length\n",
    "    \n",
    "    clipped_low_stress_edge = low_stress_polylines.clip(polygon)\n",
    "    clipped_low_stress['edge_length'] = clipped_low_stress_edge['geometry'].length\n",
    "    \n",
    "    clipped_streets_edge = all_streets_polylines.clip(polygon)\n",
    "    clipped_streets['edge_length'] = clipped_streets_edge['geometry'].length\n",
    "\n",
    "    # calculate a weighting factor for clipped edges\n",
    "    clipped_bike['weights'] = clipped_bike['edge_length']/clipped_bike['geometry'].length\n",
    "    clipped_low_stress['weights'] = clipped_low_stress['edge_length']/clipped_low_stress['geometry'].length\n",
    "    clipped_streets['weights'] = clipped_streets['edge_length']/clipped_streets['geometry'].length\n",
    "\n",
    "    # Create a multigraph of nodes and edges where roads intersect\n",
    "    bike_G = momepy.gdf_to_nx(clipped_bike, approach=\"primal\")\n",
    "    low_stress_G = momepy.gdf_to_nx(clipped_low_stress, approach=\"primal\")\n",
    "    street_G = momepy.gdf_to_nx(clipped_streets, approach=\"primal\")\n",
    "    \n",
    "    # Getting nodes and edges\n",
    "    \n",
    "    if len(bike_G.nodes) > 0: # since the bike network is small, there are some polygons where there are no nodes or edges\n",
    "        bike_nodes, bike_edges, bike_weights = momepy.nx_to_gdf(bike_G, spatial_weights=True)\n",
    "    else:\n",
    "        bike_nodes = None;\n",
    "        bike_edges = None;\n",
    "\n",
    "    low_stress_nodes, low_stress_edges, low_stress_weights = momepy.nx_to_gdf(low_stress_G, spatial_weights=True)\n",
    "    street_nodes, street_edges, street_weights = momepy.nx_to_gdf(street_G, spatial_weights=True)\n",
    "\n",
    "    # only keep nodes that join multiple edges, these act as the intersections\n",
    "    def remove_non_intersection_nodes(nodes_gdf, edges_gdf_original):\n",
    "        if nodes_gdf is not None:\n",
    "            edges_gdf = edges_gdf_original.copy()\n",
    "            if 'index_right' in edges_gdf.columns:\n",
    "                edges_gdf = edges_gdf.drop(columns=['index_right'])\n",
    "            #   buffer nodes_gdf\n",
    "            \n",
    "            \n",
    "            buffered_nodes = gpd.GeoDataFrame(geometry=nodes_gdf.buffer(distance=0.5), crs=bike_network.crs)\n",
    "            buffered_nodes = gpd.GeoDataFrame(buffered_nodes.join(nodes_gdf.drop('geometry', axis=1)))\n",
    "\n",
    "            # Spatial Join\n",
    "            merged = gpd.sjoin(edges_gdf, nodes_gdf, how='right', op='intersects')\n",
    "            \n",
    "            # Count edges per node\n",
    "            edges_count = merged.groupby('nodeID').size().reset_index(name='edge_count')     \n",
    "\n",
    "            # Merge counts back to nodes GeoDataFrame\n",
    "            nodes_gdf = nodes_gdf.merge(edges_count, left_on='nodeID', right_on='nodeID', how='left')\n",
    "            nodes_gdf['edge_count'] = nodes_gdf['edge_count'].fillna(0).astype(int)\n",
    "            nodes_gdf = nodes_gdf[nodes_gdf['edge_count'] > 1]\n",
    "        return nodes_gdf\n",
    "\n",
    "    bike_nodes = remove_non_intersection_nodes(bike_nodes, bike_edges)\n",
    "    low_stress_nodes = remove_non_intersection_nodes(low_stress_nodes, low_stress_edges)\n",
    "    street_nodes = remove_non_intersection_nodes(street_nodes, street_edges)\n",
    "\n",
    "\n",
    "    # calculating connectivity indicators\n",
    "    bike_network_density = calc_net_density(bike_edges, polygon) if bike_edges is not None else None\n",
    "    low_stress_network_density = calc_net_density(low_stress_edges, polygon)\n",
    "\n",
    "    bike_gamma = calc_gamma(street_nodes, bike_edges) if bike_edges is not None else None\n",
    "    low_stress_gamma = calc_gamma(street_nodes, low_stress_edges)\n",
    "\n",
    "    bike_network_coverage = calc_net_coverage(bike_edges, street_edges) if bike_edges is not None else None\n",
    "    low_stress_network_coverage = calc_net_coverage(low_stress_edges, street_edges)\n",
    "\n",
    "    bike_intersection_density = calc_int_density(bike_nodes, polygon) if bike_nodes is not None else None\n",
    "    low_stress_intersection_density = calc_int_density(low_stress_nodes, polygon)\n",
    "    \n",
    "    bike_network_complexity = calc_complexity(bike_edges, bike_nodes) if bike_edges is not None else None\n",
    "    low_stress_network_complexity = calc_complexity(low_stress_edges, low_stress_nodes)\n",
    "    \n",
    "    # store connectivity indicators in list\n",
    "    connectivity_indicators_list['GEOID'].append(id)\n",
    "    \n",
    "    connectivity_indicators_list['b_net_dens'].append(bike_network_density)\n",
    "    connectivity_indicators_list['ls_net_dens'].append(low_stress_network_density)\n",
    "    \n",
    "    connectivity_indicators_list['b_gamma'].append(bike_gamma)\n",
    "    connectivity_indicators_list['ls_gamma'].append(low_stress_gamma)\n",
    "    \n",
    "    connectivity_indicators_list['b_cover'].append(bike_network_coverage)\n",
    "    connectivity_indicators_list['ls_cover'].append(low_stress_network_coverage)\n",
    "\n",
    "    connectivity_indicators_list['b_int_dens'].append(bike_intersection_density)\n",
    "    connectivity_indicators_list['ls_int_dens'].append(low_stress_intersection_density)\n",
    "\n",
    "    connectivity_indicators_list['b_complex'].append(bike_network_complexity)\n",
    "    connectivity_indicators_list['ls_complex'].append(low_stress_network_complexity)\n",
    "\n",
    "    # store edges and nodes\n",
    "    if bike_edges is not None:\n",
    "        bike_edges['GEOID'] = id\n",
    "        bike_edges_list.append(bike_edges)\n",
    "    if bike_nodes is not None:\n",
    "        bike_nodes['GEOID'] = id\n",
    "        bike_nodes_list.append(bike_nodes)\n",
    "    low_stress_edges['GEOID'] = id\n",
    "    low_stress_edges_list.append(low_stress_edges)\n",
    "    low_stress_nodes['GEOID'] = id\n",
    "    low_stress_nodes_list.append(low_stress_nodes)\n",
    "    street_edges['GEOID'] = id\n",
    "    street_edges_list.append(street_edges)\n",
    "    street_nodes['GEOID'] = id\n",
    "    street_nodes_list.append(street_nodes)\n",
    "    \n",
    "# Convert the list to a new DataFrame\n",
    "connectivity_indicators_df = pd.DataFrame.from_dict(connectivity_indicators_list)\n",
    "\n",
    "# Merge dataframe with blocks geodataframe on GEOID attribute\n",
    "connectivity_blocks = blocks.merge(connectivity_indicators_df, on='GEOID')\n",
    "\n",
    "# save updated census blocks to new file\n",
    "connectivity_blocks.to_file(output_blocks_path, driver='ESRI Shapefile', if_exists='replace')\n",
    "\n",
    "# convert edges + nodes to one gdf and save\n",
    "nodes_list = [bike_nodes_list, low_stress_nodes_list, street_nodes_list]\n",
    "nodes_name = [\"bike_nodes\", \"low_stress_nodes\", \"street_nodes\"]\n",
    "nodes_file = './outputs/nodes/'\n",
    "index = -1\n",
    "for node in nodes_list:\n",
    "    index += 1\n",
    "    merged_nodes = gpd.GeoDataFrame(pd.concat(node, ignore_index=True), crs=node[0].crs)\n",
    "    merged_nodes.to_file(nodes_file +nodes_name[index], driver='ESRI Shapefile', if_exists='replace')\n",
    "\n",
    "edges_list = [bike_edges_list, low_stress_edges_list, street_edges_list]\n",
    "edges_name = [\"bike_edges\", \"low_stress_edges\", \"street_edges\"]\n",
    "edges_file = './outputs/edges/'\n",
    "index = -1\n",
    "for edge in edges_list:\n",
    "    index += 1\n",
    "    merged_edges = gpd.GeoDataFrame(pd.concat(edge, ignore_index=True), crs=edge[0].crs)\n",
    "    merged_edges.to_file(edges_file + edges_name[index], driver='ESRI Shapefile', if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
