{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "def initiate_path(path_temp):\n",
    "    path_round_about_temp = f'{path_temp}/roundabout'\n",
    "    path_network_temp = f'{path_temp}/networks'\n",
    "    os.makedirs(f'{path_temp}',exist_ok = True)\n",
    "    os.makedirs(f'{path_temp}/deadend',exist_ok = True)\n",
    "    os.makedirs(f'{path_temp}/finals',exist_ok = True)\n",
    "    os.makedirs(f'{path_temp}/networks',exist_ok = True)\n",
    "    os.makedirs(f'{path_temp}/rearrange',exist_ok = True)\n",
    "    os.makedirs(f'{path_temp}/roundabout',exist_ok = True)\n",
    "    os.makedirs(f'{path_temp}/test_data',exist_ok = True)\n",
    "    os.makedirs(f'{pjr_loc}/Data',exist_ok = True)\n",
    "    os.makedirs(f'{path_to_save}',exist_ok = True)\n",
    "    return path_round_about_temp, path_network_temp\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "from osmnx import io\n",
    "import glob\n",
    "\n",
    "project_crs = 'epsg:3857'\n",
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.geometry import Polygon, Point, LineString, MultiPolygon, MultiPoint\n",
    "import math\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import shutil\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from momepy import remove_false_nodes,extend_lines\n",
    "pjr_loc = os.path.dirname(os.getcwd())\n",
    "path_all = f'{pjr_loc}/Data'\n",
    "all_test = False # when the code should run only for test (my test area is Santa Barbara)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#region\n",
    "def length_of_parallel(my_s_join: GeoDataFrame, the_buffer: GeoSeries, geo_field: str) -> int:\n",
    "    my_s_join['geometry'] = my_s_join[geo_field]\n",
    "    new_data_0 = my_s_join.sjoin(GeoDataFrame(geometry=the_buffer, crs=project_crs), how='inner').reset_index()\n",
    "    if len(new_data_0) == 0:\n",
    "        return 0\n",
    "    return len(new_data_0[new_data_0['index'] != new_data_0['index_right']])\n",
    "def check_parallelism(to_translate: GeoDataFrame, is_test_local: bool = False) -> bool:\n",
    "    my_buffer = to_translate['geometry'].buffer(cap_style=2, distance=30, join_style=3)\n",
    "    to_translate['geometry_right'] = to_translate['geometry'].apply(lambda x: x.parallel_offset(35, 'right'))\n",
    "    to_translate['geometry_left'] = to_translate['geometry'].apply(lambda x: x.parallel_offset(35, 'left'))\n",
    "    # Currently is it not working\n",
    "    if is_test_local:\n",
    "        # to_translate.drop(columns= ['geometry', new_geometry[0]]).rename(columns = {new_geometry[1]: 'geometry'}).to_file(f'{path}/test_data/res_translate_{new_geometry[1]}.shp')\n",
    "        # to_translate.drop(columns= ['geometry', new_geometry[1]]).rename(columns = {new_geometry[0]: 'geometry'}).to_file(f'{path}/test_data/res_translate_{new_geometry[0]}.shp')\n",
    "        my_buffer.to_file(f'{path}/test_data/buffers_test.shp')\n",
    "    if length_of_parallel(to_translate, my_buffer, 'geometry_right') > 0 or length_of_parallel(to_translate, my_buffer,                                                                                     'geometry_left') > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def simplify(my_polygon: Polygon, x: (int, float)) -> Polygon:\n",
    "    simplify_poly = my_polygon.simplify(x, preserve_topology=False)\n",
    "    if simplify_poly.area < 50:\n",
    "        simplify_poly = simplify(my_polygon, x / 2)\n",
    "    return simplify_poly\n",
    "def create_center_line(one_poly):\n",
    "    \"\"\"\n",
    "    This method calculate new line between the farthest points of the simplified polygon\n",
    "    :param one_poly:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pnt_list = one_poly.exterior.coords[:-1]\n",
    "    list_shp = [Point(item) for item in pnt_list]\n",
    "    dis, dis_2, dis_3 = 0, 0, 0\n",
    "    third_dis = (-1, -1)\n",
    "    # The new line will be determined by the second-farthest points\n",
    "    for k, point in enumerate(list_shp):\n",
    "        j = k\n",
    "        for point2 in list_shp[k + 1:]:\n",
    "            j += 1\n",
    "            temp_dis = point.distance(point2)\n",
    "            if temp_dis > dis:\n",
    "                dis = point.distance(point2)\n",
    "            elif temp_dis > dis_2:\n",
    "                dis_2 = point.distance(point2)\n",
    "            elif temp_dis > dis_3:\n",
    "                third_dis = (k, j)\n",
    "                dis_3 = point.distance(point2)\n",
    "    if is_test:\n",
    "        dic_sim = {'index': [0], 'geometry': one_poly}\n",
    "        GeoDataFrame(dic_sim, crs='epsg:3857').to_file(f'{path}/test_data/simplify_poly_{unit[0]}_{id_pol + 2}.shp')\n",
    "    max_dist['name'].extend([id_pol + 2, id_pol + 2])\n",
    "    max_dist['geometry'].extend([list_shp[third_dis[0]], list_shp[third_dis[1]]])\n",
    "def update_df_with_center_line(new_line):\n",
    "    \"\"\"\n",
    "    update our dictionary with new lines\n",
    "    :param new_line:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dic_final['name'].append(name)\n",
    "    # dic_final['geometry'].append(LineString(coordinates=(pnt_list[max_dis[0]], pnt_list[max_dis[1]])))\n",
    "    dic_final['geometry'].append(new_line)\n",
    "    dic_final['highway'].append(data.iloc[0]['highway'])\n",
    "    dic_final['bearing'].append(data['angle'].mean())\n",
    "    dic_final['group'].append(unit[0])\n",
    "\n",
    "def update_list(line_local):\n",
    "    \"\"\"\n",
    "    add the first start/end point into the list\n",
    "    :param line_local:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    list_pnts_of_line_group.extend([Point(line_local.coords[0]), Point(line_local.coords[-1])])\n",
    "\n",
    "def add_more_pnts_to_new_lines(pnt_f_loc: Point, pnt_l_loc: Point, line_pnts: list) -> list:\n",
    "    \"\"\"\n",
    "    This method checks if more points should be added to the new lines by checking along the new line if the distance to the old network roads are more than 10 meters\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Calculate distance and azimuth between the first and last point\n",
    "    dist = pnt_f_loc.distance(pnt_l_loc)\n",
    "    x_0 = pnt_f_loc.coords[0][0]\n",
    "    y_0 = pnt_f_loc.coords[0][1]\n",
    "    bearing = math.atan2(pnt_l_loc.coords[0][0] - x_0, pnt_l_loc.coords[0][1] - y_0)\n",
    "    bearing = bearing + 2 * math.pi if bearing < 0 else bearing\n",
    "    # Calculate the number of  checks going to carry out\n",
    "    loops = int(dist / 100)\n",
    "\n",
    "    # Calculate  the first point over the line\n",
    "    for dis_on_line in range(1, loops):\n",
    "        x_new = x_0 + 100 * dis_on_line * math.sin(bearing)\n",
    "        y_new = y_0 + 100 * dis_on_line * math.cos(bearing)\n",
    "        # S_joins to all the network lines (same name and group)\n",
    "        # if the distance is less than 10 meters continue, else: find the projection point and add it to the correct location and run the function agein\n",
    "        one_pnt_df = GeoDataFrame(geometry=[Point(x_new, y_new)], crs=project_crs)\n",
    "        s_join_loc = one_pnt_df.sjoin_nearest(data, distance_col='dis').iloc[0]\n",
    "        if s_join_loc['dis'] > 10:\n",
    "            pnt_med = s_join_loc['geometry']\n",
    "            line = data.loc[s_join_loc['index_right']]['geometry']\n",
    "            line_pnts.append(line.interpolate(line.project(pnt_med)))\n",
    "            line_pnts = add_more_pnts_to_new_lines(pnt_med, pnt_l_loc, line_pnts)\n",
    "            return line_pnts\n",
    "    return line_pnts\n",
    "\n",
    "#Intersection\n",
    "#Split in intersection\n",
    "class Intersection:\n",
    "    def __init__(self,network,number:int):\n",
    "        \"\"\"\n",
    "\n",
    "        :param network:\n",
    "        :param number: give a unique name to the files created during the process (this class will be use again in this code)\n",
    "        \"\"\"\n",
    "        self.my_network = network\n",
    "        self.inter_pnt_dic = {'geometry':[],'name':[]}\n",
    "        self.lines_to_delete =[]\n",
    "        self.num = number\n",
    "    def delete_false_intersection(self):\n",
    "        # First clean all the false node\n",
    "        self.my_network = remove_false_nodes(self.my_network)\n",
    "        # the previous function has changed the topology so the length should be updated\n",
    "        self.my_network['length'] =self.my_network.length\n",
    "        self.my_network.to_file(f'{cur_path}/remove_false_nodes_{self.num}.shp')\n",
    "\n",
    "    def intersection_network(self):\n",
    "        # Create buffer around each element\n",
    "        buffer_around_lines= self.my_network['geometry'].buffer(cap_style=3, distance=1, join_style=3)\n",
    "        buffer_around_lines.to_file(f'{cur_path}/buffer_{num}.shp')\n",
    "\n",
    "        # s_join between buffer to lines\n",
    "        s_join_0 =gpd.sjoin(left_df=GeoDataFrame(geometry=buffer_around_lines,crs=project_crs),right_df=self.my_network)\n",
    "\n",
    "        # delete lines belong to the buffer\n",
    "        s_join = s_join_0[s_join_0.index!=s_join_0['index_right']]\n",
    "        s_join.to_file(f'{cur_path}/s_join_{self.num}.shp')\n",
    "\n",
    "        # Find new intersections that are not at the beginning or end of the line\n",
    "\n",
    "        s_join.apply(self.find_intersection_points, axis=1)\n",
    "        if len(self.inter_pnt_dic)==0:\n",
    "            self.my_network.reset_index().to_file(f'{cur_path}/split_{self.num}.shp')\n",
    "            return\n",
    "        inter_pnt_gdf = GeoDataFrame(self.inter_pnt_dic,crs=project_crs)\n",
    "        inter_pnt_gdf.to_file(f'{cur_path}/inter_pnt_{self.num}.shp')\n",
    "\n",
    "        # Split string line by points\n",
    "        segments = {'geometry':[],'org_id':[]}\n",
    "        # Groupby points name (which is the line they should split)\n",
    "        for group_pnts in inter_pnt_gdf.groupby('name'):\n",
    "            points  = group_pnts[1]\n",
    "            points['is_split'] = True\n",
    "\n",
    "            # get the line to split by comparing the name\n",
    "            row = self.my_network.loc[group_pnts[0]]\n",
    "            current = list(row.geometry.coords)\n",
    "            points_line = [Point(x) for x in current]\n",
    "            points_line_gdf = GeoDataFrame(geometry=points_line,crs=project_crs)\n",
    "            points_line_gdf['is_split'] = False\n",
    "\n",
    "            # append all the points together (line points and split points)\n",
    "            line_all_pnts = points_line_gdf.append(points)\n",
    "\n",
    "            # Find the distance of each point form the begining of the line on the line.\n",
    "            line_all_pnts['dis_from_the_start'] = line_all_pnts['geometry'].apply(lambda x:row.geometry.project(x))\n",
    "            line_all_pnts.sort_values('dis_from_the_start',inplace=True)\n",
    "\n",
    "            # split the line\n",
    "            seg =[]\n",
    "            for point in line_all_pnts.iterrows():\n",
    "                prop = point[1]\n",
    "                seg.append(prop['geometry'])\n",
    "                if prop['is_split']:\n",
    "                    segments['geometry'].append(LineString(seg))\n",
    "                    segments['org_id'].append(row.name)\n",
    "                    seg = [prop['geometry']]\n",
    "            # if the split point is the last one, you don't need to create new segment\n",
    "            if len(seg)>1:\n",
    "                segments['geometry'].append(LineString(seg))\n",
    "                segments['org_id'].append(row.name)\n",
    "        network_split = GeoDataFrame(data=segments,crs=project_crs)\n",
    "        cols_no_geometry = self.my_network.columns[:-1]\n",
    "        network_split_final = network_split.set_index('org_id')\n",
    "        network_split_final[cols_no_geometry] =self.my_network[cols_no_geometry]\n",
    "        network_split_final.to_file(f'{cur_path}/only_split_{self.num}.shp')\n",
    "        # remove old and redundant line from our network and update with new one\n",
    "        network_split =self.my_network.drop(index=network_split_final.index.unique()).append(network_split_final).drop(index= self.lines_to_delete)\n",
    "        network_split['length'] = network_split.length\n",
    "        self.my_network = network_split\n",
    "        self.my_network.reset_index().to_file(f'{cur_path}/split_{self.num}.shp')\n",
    "\n",
    "    def find_intersection_points(self,row):\n",
    "        r\"\"\"\n",
    "        find the intersection points between the two lines\n",
    "        :param row:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            line_1 = self.my_network.loc[row.name]\n",
    "            line_2 =  self.my_network.loc[row['index_right']]\n",
    "            pnt = line_1.geometry.intersection(line_2.geometry)\n",
    "            # If there are more than one intersection between two lines, one of the lines should be deleted.\n",
    "            if isinstance(pnt,LineString):\n",
    "                return\n",
    "            if isinstance(pnt,MultiPoint):\n",
    "                temp_line= line_1.name if line_1.length< line_2.length else line_2.name\n",
    "                if temp_line not in self.lines_to_delete:\n",
    "                    self.lines_to_delete.append(temp_line)\n",
    "                return\n",
    "            # If it is first or end continue OR if there is no intersection between the two lines\n",
    "            if len(pnt.coords)==0 or pnt.coords[0]==line_1.geometry.coords[0] or pnt.coords[0]==line_1.geometry.coords[-1]:\n",
    "                return\n",
    "            self.inter_pnt_dic['geometry'].append(pnt)\n",
    "            self.inter_pnt_dic['name'].append(row.name)\n",
    "        except:\n",
    "            print(f\"{row.name},{row['index_right']}:{pnt}\")\n",
    "\n",
    "\n",
    "#Roundabout\n",
    "class EnvEntity:\n",
    "        def __init__(self,network):\n",
    "            self.dead_end_fd = None\n",
    "            self.pnt_dead_end = None\n",
    "            self.pnt_dic = {}\n",
    "            self.first_last_dic = {'geometry': [], 'line_name': [], 'position': []}\n",
    "            self.network = network\n",
    "\n",
    "\n",
    "        def __populate_pnt_dic(self,point: type, name_of_line: str):\n",
    "            \"\"\"\n",
    "            Make \"pnt_dic\" contain a list of all the lines connected to each point.\n",
    "            :param point:\n",
    "            :param name_of_line:\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            if not point in self.pnt_dic:\n",
    "                self.pnt_dic[point] = []\n",
    "            self.pnt_dic[point].append(name_of_line)\n",
    "\n",
    "        def __send_pnts(self,temp_line: GeoSeries):\n",
    "            \"\"\"\n",
    "            # Send the first and the last points to populate_pnt_dic\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            my_geom = temp_line['geometry']\n",
    "            self.__populate_pnt_dic(my_geom.coords[0], temp_line.name)\n",
    "            self.__populate_pnt_dic(my_geom.coords[-1], temp_line.name)\n",
    "\n",
    "        def get_deadend_gdf(self,delete_short:int =30)-> GeoDataFrame:\n",
    "            self.network.apply(self.__send_pnts, axis=1)\n",
    "\n",
    "            deadend_list = [item[1][0] for item in self.pnt_dic.items() if len(item[1]) == 1]\n",
    "            pnt_dead_end_0 = [item for item in self.pnt_dic.items() if len(item[1]) == 1] # Retain all the line points with deadened\n",
    "            self.pnt_dead_end = [Point(x[0]) for x in pnt_dead_end_0]\n",
    "            # Create shp file of deadened_pnts\n",
    "            geometry,line_name = 'geometry','line_name'\n",
    "            pnt_dead_end_df = GeoDataFrame(data=pnt_dead_end_0)\n",
    "            pnt_dead_end_df[geometry]= pnt_dead_end_df[0].apply(lambda x:Point(x))\n",
    "            pnt_dead_end_df[line_name] = pnt_dead_end_df[1].apply(lambda x:x[0])\n",
    "            pnt_dead_end_df.crs = project_crs\n",
    "            pnt_dead_end_df[[geometry,line_name]].to_file(f'{path_deadend}/deadend_gdf_pnt.shp')\n",
    "            self.dead_end_fd = pnt_dead_end_df\n",
    "\n",
    "            if delete_short>0:\n",
    "                # If it is necessary to eliminate dead-end short segments, it is  important to delete them from the network geodataframe.\n",
    "\n",
    "                deadend_gdf =self.network.loc[deadend_list]\n",
    "                self.network.drop(index=deadend_gdf[deadend_gdf.length<delete_short].index,inplace=True)\n",
    "                return deadend_gdf[deadend_gdf.length>delete_short]\n",
    "            return self.network.loc[deadend_list]\n",
    "\n",
    "        def update_the_current_network(self,temp_network):\n",
    "            r\"\"\"\n",
    "            Update the current network in the new changes\n",
    "            :param temp_network:\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            new_network_temp = self.network.drop(index=temp_network.index)\n",
    "            self.network = new_network_temp.append(temp_network)\n",
    "            self.network['length'] = self.network.length\n",
    "            self.network  = self.network[self.network['length']>1]\n",
    "class Roundabout(EnvEntity):\n",
    "    def __init__(self,network: GeoDataFrame):\n",
    "       EnvEntity.__init__(self,network)\n",
    "       self.pnt_dic ={}\n",
    "       self.centroid =self.__from_roundabout_to_centroid()\n",
    "       self.network.rename(columns={'name': 'str_name'}, inplace=True)\n",
    "    def __from_roundabout_to_centroid(self):\n",
    "        # Find the center of each roundabout\n",
    "        # create polygon around each polygon and union\n",
    "        round_about = gpd.read_file(f'{path_round_about}/roundabout.shp')\n",
    "        round_about_buffer = round_about.to_crs(project_crs)['geometry'].buffer(cap_style=1, distance=10,\n",
    "                                                                                join_style=1).unary_union\n",
    "        dic_data = {'name': [], 'geometry': []}\n",
    "        if round_about_buffer.type=='Polygon': # In case we have only one polygon\n",
    "            dic_data['name'].append(0)\n",
    "            dic_data['geometry'].append(round_about_buffer.centroid)\n",
    "        else:\n",
    "            for ii, xx in enumerate(round_about_buffer):\n",
    "                dic_data['name'].append(ii)\n",
    "                dic_data['geometry'].append(xx.centroid)\n",
    "        centroid =GeoDataFrame(dic_data, crs=project_crs)\n",
    "        centroid.to_file(f'{path_round_about}/centroid.shp')\n",
    "        return centroid\n",
    "        # GeoDataFrame(dic_data,crs=project_crs).to_file(f'{path_round_about}/roundabout_union.shp')\n",
    "\n",
    "    def __first_last_pnt_of_line(self,row: GeoSeries):\n",
    "        r\"\"\"\n",
    "        It get geometry of line and fill the first_last_dic with the first and last point and the name of the line\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        geo = list(row['geometry'].coords)\n",
    "        self.first_last_dic['geometry'].extend([Point(geo[0]), Point(geo[-1])])\n",
    "        self.first_last_dic['line_name'].extend([row.name] * 2)\n",
    "        self.first_last_dic['position'].extend([0, -1])\n",
    "    def deadend(self,path_to_save: str, export_files: bool = False):\n",
    "        r\"\"\"\n",
    "        remove not connected line shorter than 100 meters and then return deadend_list lines and their endpoints (as another file)\n",
    "        :param path_to_save:\n",
    "        :param export_files:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Find the first and last points\n",
    "\n",
    "        # Get deadend_gdf\n",
    "        deadend_gdf = self.get_deadend_gdf()\n",
    "\n",
    "        # Create gdf of line points with the reference to the line they belong\n",
    "        deadend_gdf.apply(self.__first_last_pnt_of_line, axis=1)\n",
    "        first_last_gdf = GeoDataFrame(self.first_last_dic, crs=project_crs)\n",
    "\n",
    "        if export_files:\n",
    "            # Optional - Create new file\n",
    "            temp_list = {}\n",
    "            temp_list ['geometry'] = [Point(x) for x in self.pnt_dic.keys()]\n",
    "            temp_list ['lines']  = [str(x) for x in self.pnt_dic.values()]\n",
    "            GeoDataFrame(temp_list,crs=project_crs).to_file(f'{path_deadend}/line_pnts.shp')\n",
    "            first_last_gdf.to_file(f'{path_to_save}/first_last_pnts.shp')\n",
    "            deadend_gdf.to_file(f'{path_to_save}/deadend_gdf_all.shp')\n",
    "\n",
    "        return deadend_gdf, first_last_gdf\n",
    "    def __update_geometry(self,cur,s_join):\n",
    "        r\"\"\"\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if cur['highway'] == 'footway':\n",
    "            # Don't snap footway to roundabout\n",
    "            return cur['geometry']\n",
    "        # Get only the points that are deadened\n",
    "        points_lines = [item for item in s_join[s_join['line_name'] == cur.name].iterrows()if item[1]['geometry'] in my_roundabout.pnt_dead_end]\n",
    "        if len(points_lines) == 0:\n",
    "            # No roundabout nearby\n",
    "            return cur['geometry']\n",
    "        # get the line geometry to change the first and/ or last point\n",
    "        geo_cur = list(cur['geometry'].coords)\n",
    "\n",
    "        # iterate over the deadened points  near roundabout\n",
    "        for ind in range(len(points_lines)):\n",
    "            points_line = points_lines[ind]\n",
    "            geo_cur[points_line[1]['position']] = my_roundabout.centroid.loc[points_line[1]['index_right']]['geometry'].coords[\n",
    "                0]\n",
    "        return LineString(geo_cur)\n",
    "    def my_spatial_join(self,deadend_lines, deadend_pnts):\n",
    "        # Spatial join between roundabout centroid to nearby dead end lines\n",
    "        # centroid = gpd.read_file(f'{path_round_about}/centroid.shp')\n",
    "        s_join = gpd.sjoin_nearest(left_df=deadend_pnts, right_df=self.centroid, how='left', max_distance=100,\n",
    "                                   distance_col='dist').dropna(subset='dist')\n",
    "        s_join.to_file(f'{path_deadend}/roundabout_near_pnts.shp')\n",
    "\n",
    "        # Deadened lines from both lines should be removed\n",
    "        lines_to_delete_test = s_join['line_name'].unique() # all the Deadened lines close to roundabout\n",
    "\n",
    "        # All deadened lines from both lines\n",
    "        deads_both_side = my_roundabout.dead_end_fd['line_name'].value_counts()\n",
    "        deads_both_side =deads_both_side[deads_both_side==2]\n",
    "\n",
    "        # Remove this lines from the database\n",
    "        lines_to_delete=deads_both_side[deads_both_side.index.isin(lines_to_delete_test)]\n",
    "\n",
    "        self.network = self.network[~((self.network[line_name].isin(lines_to_delete.index)) & (self.network.length<300))]\n",
    "        deadend_lines = deadend_lines[~((deadend_lines[line_name].isin(lines_to_delete.index)) & (deadend_lines.length<300))]\n",
    "        # Update the geometry so the roundabout will be part of the line geometry\n",
    "        change_geo = deadend_lines.copy()\n",
    "\n",
    "        change_geo['geometry'] = change_geo.apply(lambda x:self.__update_geometry(x,s_join), axis=1)\n",
    "        change_geo.reset_index().to_file(f'{path_deadend}/connect_roundabout.shp')\n",
    "        return change_geo\n",
    "\n",
    "#endregion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "path = f'{pjr_loc}/process'\n",
    "name_c = 'Santa Barbara'\n",
    "path_to_save  = f'{path_all}/{name_c}' # The raw data and the final results will be saved\n",
    "path_round_about, path_network = initiate_path(path)\n",
    "\n",
    "graph = ox.graph_from_place('Santa Barbara,California', network_type='all')\n",
    "graph = ox.bearing.add_edge_bearings(graph, precision=1)\n",
    "graph_pro = ox.projection.project_graph(graph, to_crs=project_crs)\n",
    "\n",
    "\n",
    "io.save_graph_geopackage(graph_pro, filepath='Santa_Barbara.gpkg', encoding='utf-8', directed=False)\n",
    "\n",
    "my_gdf = gpd.read_file('Santa_Barbara.gpkg',layer = 'edges')\n",
    "\n",
    "\n",
    "#region\n",
    "is_junction= True if 'junction' in my_gdf.columns else False\n",
    "if is_junction:\n",
    "    # delete segments present any kind of roundabout if exist\n",
    "    round_about = my_gdf[my_gdf['junction'].isin(['roundabout', 'circular'])]\n",
    "    round_about.to_file(f'{path_round_about}/roundabout.shp')\n",
    "    my_gdf= my_gdf[~((my_gdf['junction'] == 'roundabout') | (my_gdf['junction'] == 'circular'))]\n",
    "\n",
    "# delete more irrelevant objects\n",
    "if 'tunnel' in my_gdf.columns:\n",
    "    my_gdf = my_gdf[~((my_gdf['tunnel'] == 'building_passage') | (my_gdf['tunnel'] == 'yes'))]\n",
    "to_remove = my_gdf[~((my_gdf['highway'] == 'motorway') | (my_gdf['highway'] == 'trunk')| (my_gdf['highway'] == 'motorway_link')| (my_gdf['highway'] == 'motorway_link')| (my_gdf['highway'] == 'trunk_link'))]\n",
    "# Apply the function to all columns in the DataFrame\n",
    "# to_remove = to_remove.applymap(update_lists)\n",
    "to_remove.to_file(f'{path_network}/to_remove.shp')\n",
    "# Project dataframe and calculate angle (0 to 180)\n",
    "df_pro = to_remove.to_crs(project_crs).dropna(subset=['name'])\n",
    "df_pro = df_pro[df_pro['name']!='']\n",
    "df_pro['angle'] = df_pro['bearing'].apply(lambda x: x if x < 180 else x - 180)\n",
    "df_pro['length'] = df_pro.length\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_pro.to_file(f'{path_network}/pro.shp')\n",
    "#endregion\n",
    "#region\n",
    "# Main point to start\n",
    "df_pro = gpd.read_file(f'{path_network}/pro.shp')\n",
    "is_test = False\n",
    "my_groupby = df_pro.groupby('name')\n",
    "dic_final = {'name': [], 'geometry': [], 'highway': [], 'bearing': [], 'group': []}\n",
    "\n",
    "for_time = len(my_groupby)\n",
    "for i, street in enumerate(my_groupby):\n",
    "    # Calculate time to run\n",
    "    print(f'{round(i / for_time * 100, 2)}\\t', end=\"\")\n",
    "    res = street[1]\n",
    "    name = street[0]\n",
    "    if is_test:\n",
    "        name = 'State Street'\n",
    "        res = my_groupby.get_group(name)\n",
    "    # groupby angle\n",
    "    res = res.dropna(subset=['angle'], axis=0)\n",
    "    if len(res) == 0:\n",
    "        continue\n",
    "    res['group'] = DBSCAN(eps=5, min_samples=2).fit(res['angle'].to_numpy().reshape(-1, 1)).labels_\n",
    "    cur_group = res[res['group'] > -1].groupby('group')\n",
    "    is_parallel = False\n",
    "    for group in cur_group:\n",
    "        data = group[1]\n",
    "        if check_parallelism(data, is_test):\n",
    "            # if among of lines with same angles some are parallel,find the center line for each group\n",
    "            is_parallel = True\n",
    "            for unit in cur_group:\n",
    "                data = unit[1]\n",
    "\n",
    "                # new points DataFrame of start/end line of each group\n",
    "                list_pnts_of_line_group = []\n",
    "                data['geometry'].apply(update_list)\n",
    "                df_pnts = GeoDataFrame(geometry=list_pnts_of_line_group, crs='epsg:3857').drop_duplicates()\n",
    "\n",
    "                # unify lines to one polygon\n",
    "                buffers = data.buffer(cap_style=3, distance=30, join_style=3)\n",
    "                one_buffer = buffers.unary_union\n",
    "\n",
    "                max_dist = {'name': [], 'geometry': []}\n",
    "                # simplify polygon with simplify function. If one_buffer is multipolygon object simplify each one them separately\n",
    "                if isinstance(one_buffer, MultiPolygon):\n",
    "                    for id_pol, polygon in enumerate(one_buffer):\n",
    "                        create_center_line(polygon)\n",
    "                else:\n",
    "                    id_pol = -1\n",
    "                    create_center_line(one_buffer)\n",
    "                max_df = GeoDataFrame(max_dist, crs='epsg:3857')\n",
    "                # find for each points the closet point from the oribinal data. the closet points will create the new line\n",
    "                s_join = max_df.sjoin_nearest(df_pnts).groupby('name')\n",
    "                for geo in s_join:\n",
    "                    same_name = geo[1]\n",
    "                    if same_name.iloc[0]['index_right'] == same_name.iloc[1]['index_right']:\n",
    "                        continue\n",
    "                    in_0 = same_name.iloc[0]['index_right']\n",
    "                    in_1 = same_name.iloc[1]['index_right']\n",
    "                    # These points will be served to be initial reference in order to find more points\n",
    "                    pnt_f = df_pnts.loc[in_0]['geometry']\n",
    "                    pnt_l = df_pnts.loc[in_1]['geometry']\n",
    "                    lines_pnt_geo = add_more_pnts_to_new_lines(pnt_f, pnt_l, [pnt_f])\n",
    "                    lines_pnt_geo.append(pnt_l)\n",
    "                    # Update dic_final\n",
    "                    update_df_with_center_line(LineString(lines_pnt_geo))\n",
    "                    # dic_final['geometry'].append(LineString(lines_pnt_geo))\n",
    "                    # new_lines['name'].append(geo[0])\n",
    "                if is_test:\n",
    "                    buffers.to_file(f'{path}/test_data/buffers_{unit[0]}.shp')\n",
    "                    # dic_one = {'index':[0],'geometry':one_buffer.geoms}\n",
    "                    # GeoDataFrame(dic_one,crs='epsg:3857').to_file(f'{path}/test_data/one_buffer_{unit[0]}.shp')\n",
    "        # if one group is found as parallel all the groups are calculated as parallel so we don't need to check_parallelism\n",
    "        if is_parallel:\n",
    "            break\n",
    "    # # טסט\n",
    "    if is_test:\n",
    "        final = GeoDataFrame(dic_final, crs=project_crs)\n",
    "        final = final[final.length > 20]\n",
    "        final.to_file(f'{path}/test_data/one_line.shp')\n",
    "        res.to_file(f'{path}/test_data/groups.shp')\n",
    "        break\n",
    "\n",
    "if not is_test:\n",
    "    print('create new files')\n",
    "    # remove short lines\n",
    "    final_cols = ['name', 'geometry', 'highway', 'bearing', 'length']\n",
    "    final = GeoDataFrame(dic_final, crs=project_crs)\n",
    "    final['is_simplify'] = 1\n",
    "    final.to_file(f'{path_network}/one_line_third.shp')\n",
    "    # create network\n",
    "    new_network = df_pro[~df_pro['name'].isin(dic_final['name'])][final_cols]\n",
    "    new_network['is_simplify'] = 0\n",
    "    new_network.append(final).to_file(f'{path_network}/new_network_third.shp')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num=0\n",
    "cur_path = f'{path}/rearrange'\n",
    "new_gpd = gpd.read_file(f'{path_network}/new_network_third.shp')\n",
    "obj_intersection = Intersection(new_gpd,num)\n",
    "obj_intersection.delete_false_intersection()\n",
    "obj_intersection.intersection_network()\n",
    "\n",
    "\n",
    "# Network Improvement - to roundabout\n",
    "# Find unconnected lines\n",
    "path_deadend = f'{path}/deadend'\n",
    "if is_junction:\n",
    "    line_name ='line_name'\n",
    "    exist_data= gpd.read_file(f'{cur_path}/split_{num}.shp').reset_index(names=line_name)\n",
    "    my_roundabout=Roundabout(exist_data)\n",
    "\n",
    "    deadend_lines, deadend_pnts = my_roundabout.deadend(path_to_save=path_deadend,export_files=True)\n",
    "\n",
    "\n",
    "    # update the current network\n",
    "    change_geo = my_roundabout.my_spatial_join(deadend_lines, deadend_pnts)\n",
    "    my_roundabout.update_the_current_network(change_geo)\n",
    "    print(len(my_roundabout.network))\n",
    "    my_roundabout.network.drop_duplicates(subset=line_name,inplace=True)\n",
    "    my_roundabout.network.to_file(f'{path_network}/network_ra.shp')\n",
    "    # Improve roundabout\n",
    "    # First buffer around centroid\n",
    "    centr_name= 'centr_name'\n",
    "    my_roundabout.network= gpd.read_file(f'{path_network}/network_ra.shp')\n",
    "    buffer_around_centroid= my_roundabout.centroid['geometry'].buffer(cap_style=1, distance=30)\n",
    "    buffer_around_centroid.to_file(f'{path_round_about}/buffer_around_centroid.shp')\n",
    "\n",
    "    # s_join between buffer to lines (reset index to retain the original centroid name which can apper more than one in the results). always stay with data you need and with understandable name\n",
    "    roundabout_with_lines =gpd.sjoin(left_df=GeoDataFrame(geometry=buffer_around_centroid,crs=project_crs).reset_index(),right_df=my_roundabout.network[['geometry',line_name]]).drop_duplicates(subset=['index',line_name]).rename(columns={\"index\":centr_name})[['geometry',line_name,centr_name]]\n",
    "    roundabout_with_lines.to_file(f'{path_deadend}/roundabout_with_lines.shp')\n",
    "\n",
    "    # To facilitate the searching process\n",
    "    my_roundabout.network.set_index(line_name,inplace=True)\n",
    "    print(len(my_roundabout.network))\n",
    "    # To facilitate easy access to point centroid geometry data, it is advisable to store the information in an object that provides efficient retrieval.\n",
    "    pnt_centroid_temp = my_roundabout.centroid['geometry']\n",
    "    #  Group the data by centroid\n",
    "    for center_line in roundabout_with_lines.groupby(centr_name):\n",
    "        #  Iterate over each group after performing a groupby() operation\n",
    "        for center in center_line[1].itertuples():\n",
    "            # Find the line that connects to the current centroid and obtain its vertices\n",
    "            line_to_test = my_roundabout.network.loc[center[2]]\n",
    "            vertices_line = list(line_to_test['geometry'].coords)\n",
    "            pnt_test = [vertices_line[0],vertices_line[-1]]\n",
    "            # To determine if the current line is already connected to the current centroid,.\n",
    "            is_connected = my_roundabout.centroid[my_roundabout.centroid['geometry'].isin([Point(pnt_test[0]),Point(pnt_test[-1])])]\n",
    "            if len(is_connected)>0 and center[3] in is_connected['name']:\n",
    "                continue\n",
    "\n",
    "            if len(vertices_line)==2:\n",
    "                vertices_line.insert(1, pnt_centroid_temp[center[3]])\n",
    "            else:\n",
    "                my_list = [pnt_centroid_temp[center[3]].distance(Point(temp)) for temp in vertices_line]\n",
    "                # Find the minimum index\n",
    "                min_index = min(range(len(my_list)), key=my_list.__getitem__)\n",
    "                if min_index ==0:\n",
    "                    vertices_line.insert(0,pnt_centroid_temp[center[3]])\n",
    "                elif min_index == len(my_list)-1:\n",
    "                    vertices_line.append(pnt_centroid_temp[center[3]])\n",
    "                else:\n",
    "                    vertices_line[min_index] = pnt_centroid_temp[center[3]]\n",
    "            new_geo = LineString(vertices_line)\n",
    "            my_roundabout.network.at[center[2],'geometry'] = new_geo\n",
    "    my_roundabout.network.to_file(f'{path_network}/network_ra_update.shp')\n",
    "# Extend\n",
    "    new_network2 =gpd.read_file(f'{path_network}/network_ra_update.shp')\n",
    "else:\n",
    "    new_network2=  gpd.read_file(f'{cur_path}/split_{num}.shp')\n",
    "print(len(my_roundabout.network))\n",
    "extend_lines_f= extend_lines(new_network2,100)\n",
    "extend_lines_f['length'] = extend_lines_f.length\n",
    "extend_lines_f.to_file(f'{cur_path}/extend_lines.shp')\n",
    "cur_path = f'{path}/finals'\n",
    "obj_intersection2 = Intersection(extend_lines_f,1)\n",
    "obj_intersection2.delete_false_intersection()\n",
    "obj_intersection2.intersection_network()\n",
    "# Clear short segments\n",
    "final2 = EnvEntity(obj_intersection2.my_network.reset_index())\n",
    "final2.update_the_current_network(final2.get_deadend_gdf(delete_short=30))\n",
    "final2.network.to_file(f'{path_to_save}/simp2_{name_c}.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "      line_name  index             str_name                     highway  \\\n5             5      5         Vincente Way                 residential   \n7             7      7         Vincente Way                 residential   \n14           14     14        Alamar Avenue  ['service', 'residential']   \n18           18     18  East Calle Laureles                 residential   \n22           22     23       La Jolla Drive                 residential   \n...         ...    ...                  ...                         ...   \n2595       2595   2095                 None                        None   \n2596       2596   2095                 None                        None   \n2647       2647   2158                 None                        None   \n2659       2659   2243                 None                        None   \n2660       2660   2244                 None                        None   \n\n      bearing      length  is_simplif  group  \\\n5         0.0   44.400243         0.0    NaN   \n7       200.4  128.513945         0.0    NaN   \n14      214.6  746.738866         0.0    NaN   \n18      196.0   69.409235         0.0    NaN   \n22        5.3   76.352266         0.0    NaN   \n...       ...         ...         ...    ...   \n2595      NaN  420.597643         NaN    NaN   \n2596      NaN  206.621666         NaN    NaN   \n2647      NaN  297.970397         NaN    NaN   \n2659      NaN  181.694144         NaN    NaN   \n2660      NaN   78.146091         NaN    NaN   \n\n                                               geometry  \n5     LINESTRING (-13329916.246 4086045.837, -133299...  \n7     LINESTRING (-13329872.275 4086208.324, -133299...  \n14    LINESTRING (-13327273.666 4089675.074, -133272...  \n18    LINESTRING (-13327982.782 4089346.439, -133279...  \n22    LINESTRING (-13328638.187 4082483.725, -133286...  \n...                                                 ...  \n2595  LINESTRING (-13323333.134 4089232.059, -133235...  \n2596  LINESTRING (-13323430.004 4088952.703, -133234...  \n2647  LINESTRING (-13322455.685 4085435.725, -133224...  \n2659  LINESTRING (-13318437.389 4085516.490, -133182...  \n2660  LINESTRING (-13318805.993 4085564.517, -133188...  \n\n[504 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_name</th>\n      <th>index</th>\n      <th>str_name</th>\n      <th>highway</th>\n      <th>bearing</th>\n      <th>length</th>\n      <th>is_simplif</th>\n      <th>group</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>5</td>\n      <td>Vincente Way</td>\n      <td>residential</td>\n      <td>0.0</td>\n      <td>44.400243</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13329916.246 4086045.837, -133299...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7</td>\n      <td>Vincente Way</td>\n      <td>residential</td>\n      <td>200.4</td>\n      <td>128.513945</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13329872.275 4086208.324, -133299...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>14</td>\n      <td>Alamar Avenue</td>\n      <td>['service', 'residential']</td>\n      <td>214.6</td>\n      <td>746.738866</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13327273.666 4089675.074, -133272...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>18</td>\n      <td>East Calle Laureles</td>\n      <td>residential</td>\n      <td>196.0</td>\n      <td>69.409235</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13327982.782 4089346.439, -133279...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>23</td>\n      <td>La Jolla Drive</td>\n      <td>residential</td>\n      <td>5.3</td>\n      <td>76.352266</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13328638.187 4082483.725, -133286...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2595</th>\n      <td>2595</td>\n      <td>2095</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>420.597643</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13323333.134 4089232.059, -133235...</td>\n    </tr>\n    <tr>\n      <th>2596</th>\n      <td>2596</td>\n      <td>2095</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>206.621666</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13323430.004 4088952.703, -133234...</td>\n    </tr>\n    <tr>\n      <th>2647</th>\n      <td>2647</td>\n      <td>2158</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>297.970397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13322455.685 4085435.725, -133224...</td>\n    </tr>\n    <tr>\n      <th>2659</th>\n      <td>2659</td>\n      <td>2243</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>181.694144</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13318437.389 4085516.490, -133182...</td>\n    </tr>\n    <tr>\n      <th>2660</th>\n      <td>2660</td>\n      <td>2244</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>78.146091</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LINESTRING (-13318805.993 4085564.517, -133188...</td>\n    </tr>\n  </tbody>\n</table>\n<p>504 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_geo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}